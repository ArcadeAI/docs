---
title: "Configuration"
description: "Arcade Engine Configuration"
---

# Configuration

This guide explains how to configure the Arcade Engine.

To start the Arcade Engine, pass a config file:

```bash
engine --config /path/to/config.yaml
```

## API Configuration

HTTP is the only supported protocol for Arcade Engine's API. The following
configurations are available:

-   `api.host` (default: localhost) - Address to which Arcade Engine binds its
    server (e.g., `localhost` or `0.0.0.0`)
-   `api.read_timeout` (default: 3m) - Timeout for reading data from clients
-   `api.write_timeout` (default: 3m) - Timeout for writing data to clients
-   `api.idle_timeout` (default: 1m) - Timeout for idle connections
-   `api.max_request_body_size` (default: 4Mb) - Maximum request body size

If you're developing locally, you can set these additional options:

-   `development` (default: false) - Enable development mode (bypasses
    authentication)

Sample configuration:

```yaml
api:
    development: false
    host: 0.0.0.0
    port: 9099
    read_timeout: 3s
    write_timeout: 3s
    idle_timeout: 1s
    max_request_body_size: 2Mi
```

## Components

Arcade Engine's configuration is a [YAML file](https://yaml.org/) with the
following sections:

-   `routers` - Defines routers per model type (e.g., `routers.language`,
    `routers.speech`). See [router types](/essentials/routers) for more details.
-   `api` - Configures the server for specific protocols. See
    [API Configuration](#api-configuration) above.
-   `telemetry` - Configures observability. See [Telemetry](#telemetry) below.

## Basic Configuration

A simple setup includes a single router and two models. This example shows a
failover router using OpenAI and Azure OpenAI. For OpenAI, Cohere, and OctoML,
only an API key is needed. For Azure OpenAI, specify a model and base_url.

-   `language` - Language API endpoint supporting `/chat` from model providers
-   `id` - Unique router ID
-   `strategy` - Router type: round-robin, weighted-round-robin, least-latency,
    priority
-   `models/id` - Unique model configuration ID

```yaml
routers:
    language:
        - id: my-chat-router
          strategy: priority
          models:
              - id: primary
                openai:
                    api_key: "${env:OPENAI_API_KEY}"
              - id: secondary
                azureopenai:
                    api_key: "${env:AZURE_OPENAI_API_KEY}"
                    model: "engine-GPT-35"
                    base_url: "https://mydeployment.openai.azure.com/"
```

See [advanced configuration](/essentials/configuration#advanced-configuration)
for more details.

## Secrets

Arcade Engine supports two methods for passing sensitive information like API
keys:

-   Environment variables:

```yaml
routers:
    language:
        - id: default
          strategy: priority
          models:
              - id: primary
                openai:
                    api_key: "${env:OPENAI_API_KEY}"
```

-   Separate files (useful in cloud setups):

```yaml
routers:
    language:
        - id: default
          strategy: priority
          models:
              - id: primary
                openai:
                    api_key: "${file:/path/to/secret}"
```

### Dotenv Files

Arcade Engine automatically loads environment variables from `.env` files in the
directory where it was called. Use the `--env` flag to specify a path:

```bash
engine --env .env.dev --config config.yaml
```

## Telemetry

Arcade supports logs, metrics, and traces with
[OpenTelemetry](https://opentelemetry.io/).

If you are using the engine locally, you can set the `environment` field to
`local`. This will only output logs to the console.

To connect to Open Telemetry compatible collectors, set necessary
[Open Telemetry Environment Variables](https://opentelemetry.io/docs/specs/otel/configuration/sdk-environment-variables/)
in the .env file.

`environment` and `version` are fields that are added to the telemetry
attributes, which can be filtered on later.

```yaml
telemetry:
    environment: local
    version: ${env:VERSION}
    logging:
        level: debug # debug, info, warn, error, fatal
        encoding: console
```

### Notes:

-   The engine service name is set to `arcade_engine`
-   Traces currently cover the `/v1/health` and `/v1/chat/completions` endpoints
    as well as authentication attempts

## Full Configuration Example

```yaml
telemetry:
    environment: local
    version: ${env:VERSION}
    logging:
        level: info # debug, info, warning, error, fatal
        encoding: json # console, json

routers:
    language:
        - id: simplerouter
          strategy: priority
          models:
              - id: openai-boring
                openai:
                    model: gpt-3.5-turbo
                    api_key: "sk-"
                    default_params:
                        temperature: 0

director:
    directors:
        - id: default
          enabled: true
          actors:
              - id: "localactor"
                enabled: true
                http:
                    uri: "http://localhost:8000"
                    timeout: 30
                    retry: 3
storage:
    token_cache:
        in_memory:
        max_size: 1000
```
