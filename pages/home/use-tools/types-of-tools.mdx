---
title: "Get Formatted Tool Definitions"
description: "Learn how to get formatted tool definitions using Arcade"
---

# Types of Tools

Arcade offers two types of tools:

- API wrapper tools
- LLM-native tools

Before we understand the two types, let's first understand the background for why we need to differentiate between them.


## Why LLMs perform poorly when calling HTTP APIs

Traditionally, the HTTP APIs offered by third-party services such as GitHub, Google, Slack, etc., were designed to be consumed by human software engineers. When we expose such interfaces for LLMs to call as tools, they usually do not perform very well.

One of the main reasons is that the data model of the HTTP API rarely matches the data model of an AI-powered chat interface.

For instance, consider the following user prompt:

> "Send a DM to John asking about a project update"

The data model mismatches are:

| Item | Chat interface | Slack HTTP API |
| --- | --- | --- |
| Action | Send message to a user | Send message to a channel |
| Argument | `username = "John"` | `channel_id = ???` |


In order to bridge the gap in the data models, the LLM has to make multiple API calls:

1. Retrieve the current user's Slack ID
2. Browse the list of users to find John's ID
3. Open a direct message between the user and John, and get the channel ID
4. Send the message to the channel

Even the most powerful LLMs usually perform poorly when they need to reason such complex workflows on the fly, not to mention the increased cost and risk of hallucinations. As a result, AI Agents and chatbots that rely on HTTP APIs often end up being unreliable.

## LLM-native tools

Arcade's LLM-native toolkits are designed to match the typical data models expected in AI-powered chat interfaces and are subject to evaluation suites to ensure LLMs can safely use them.

Following the example above, our Slack toolkit offers the [`Slack.SendMessage`](http://localhost:3000/toolkits/social-communication/slack#slacksendmessage) tool, which accepts a `username` as argument, matching exactly both the action and argument value expected to be present in the LLM context window.

When a user says "Send a DM to John asking about a project update", the LLM can directly call the `Slack.SendMessage` tool with the `username` argument, and the tool will take care of the rest.

LLM-native tools dramatically improve the speed, reliability and cost-effectiveness of AI Agents and chatbots.

Since they require careful design and evaluation, LLM-native tools take time and effort to build. We understand that your Agent or chatbot project might need capabilities not yet covered by our LLM-native toolkits. For this reason, we also offer low-level API wrapper toolkits.

## API wrapper tools

To provide your Agent or chatbot with more freedom to interact with the third-party services, we offer API wrapper toolkits.

API wrapper tools are heavily influenced by the original API design. Each tool mirrors one HTTP endpoint.

Although we redesign the tool name and argument descriptions to make them more suitable for LLMs, API wrapper tools are still not optimized for LLM usage. Also, they are not subject to evaluation suites like LLM-native tools. For those reasons, we recommend thoroughly evaluating each API wrapper tool with your Agents or chatbots before using it in production.

When your Agent's needs are covered by an LLM-native tool, we recommend using it instead of an API wrapper. Use API wrappers as a complement. Carefully engineer your prompts to ensure your Agent can call them safely.
