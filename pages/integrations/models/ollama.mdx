# Ollama

## Connecting

To send a message to Ollama, you can use the OpenAI Client. Arcade will use the OpenAI interface internally to send messages to Ollama.

```python
import os
from openai import OpenAI

client = OpenAI(
    base_url="https://api.arcade-ai.com/v1",
    api_key=os.environ.get("ARCADE_API_KEY"))


response = client.chat.completions.create(
    model = "llama3",
    user = "user@arcade-ai.com",
    messages = [
        {"role": "user", "content": "Summarize my last 10 emails"}
    ]
)
```

## Configuration

This is a simple example on enabling Ollama in the Arcade Engine

```yaml
llm:
  models:
    - id: ollama
      openai: # Use the OpenAI interface for Ollama
        base_url: http://localhost:11434
        chat_endpoint: /api/chat
```

For more advanced configuration, see the [model docs](/home/configuration/models#ollama)
