# Ollama

## Connecting

To send a message to Ollama, you can use the OpenAI Client. Arcade will use the OpenAI interface internally to send messages to Ollama.

```python
import os

from openai import OpenAI

client = OpenAI(
  base_url="http://localhost:9099/v1",
  api_key=os.environ.get("ARCADE_API_KEY")
)


response = client.chat.completions.create(
    model="ollama/llama3.2",
    user="user@arcade-ai.com",
    messages=[{"role": "user", "content": "hello"}],
    stream=False,
)
```

## Configuration

This is a simple example on enabling Ollama in the Arcade Engine

```yaml
llm:
  models:
    - id: ollama
      openai: # Use the OpenAI interface for Ollama
        base_url: http://localhost:11434
        chat_endpoint: /api/chat
```

For more advanced configuration, see the [model docs](/home/configure/models#ollama)
